# -*- coding: utf-8 -*-
"""TEAM PAPER-FLY(k-meansalgo).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c8UNMvA_kVX2Nw8BbDfKjqNFO_KXA_Hf
"""

!apt-get update
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz
!tar xf spark-3.1.1-bin-hadoop3.2.tgz
!pip install -q findspark

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.1-bin-hadoop3.2"

import findspark
findspark.init()

from pyspark.sql import SparkSession

spark = SparkSession.builder.getOrCreate()

df = spark.read.csv("/content/heart.csv",inferSchema=True,header=True)

df.show()

df.count()

len(df.columns)

df.printSchema()

df.describe().show()

df.head(5)

df.groupBy("target").count().show()

df.groupBy("age").count().show()

from pyspark.ml.linalg import Vector
from pyspark.ml.feature import VectorAssembler

df.columns

input_cols = ['age',
 'sex',
 'cp',
 'trestbps',
 'chol',
 'fbs',
 'restecg',
 'thalach',
 'exang',
 'oldpeak',
 'slope',
 'ca',
 'thal']

vec_assembler = VectorAssembler(inputCols = input_cols, outputCol= "features")

final_data = vec_assembler.transform(df)

final_data.show()

from pyspark.ml.clustering import KMeans
from pyspark.ml.evaluation import ClusteringEvaluator

kmeans = KMeans(featuresCol="features", k=2)

model = kmeans.fit(final_data)

model

model.transform(final_data).groupBy("prediction").count().show()

predictions = model.transform(final_data)

predictions.show()

predictions.groupBy("target","predIction").count().show()